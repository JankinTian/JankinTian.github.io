---
layout: post
title:  "Can a Machine Generate Humanlike Language Descriptions for a Remote Sensing Image?"
date:   2019-07-23 16:14:54
categories: 论文解读
tags: 基于模板的caption  遥感 2017年
---

* content
{:toc}
---
这篇文章主要介绍的是caption方法在遥感图像上的应用，使用的方法是：使用三元组场景元素填充模板槽以生成图像标题。与《Every picture tells a story: Generating sentences from images》中的方法很相似。
---
# 遥感caption的应用
> (1)图像检索
除了使用关键字搜索来描述需要检索的信息，    使用caption的方法可以**提高收集有用图片的可访问性**
> (2)军事情报生成

# 遥感图像和自然图像的对比
> 遥感图像和自然图像的**不同之处**：
1、遥感图像是从**“上帝视角”**分析对象的 class   dependence 和空间依赖关系。
2、遥感图像包含的**数据更加丰富**，且图片的像素较高，所以处理遥感图像具有一定的难度。

>* **(1)多级语义**
[①：像素级语义**（pixel level semantics）**；
②：目标级语义**(targel level semantics)**；
③：环境级语义**（environmental level semantics）**]
对于遥感图像，相同的地面元素可能在不同的地理尺度下呈现完全不同的语义。例如，考虑机场的遥感图像，其中像素级语义可以对应于地面材料特征，例如金属，混凝土和土壤，目标级语义可以对应于对象本身及其属性，例如飞机，航站楼和跑道，而环境级语义可能对应于更广泛的地面区域，如机场，港口，海洋或城市。
>* **(2)语义歧义**
不同的地理语义类之间可能存在一些“(gray zones)灰色区域”，特别是对于那些具有多个语义属性的大规模区域。有时，很难通过单个语义标签来表征遥感图像的特定区域。例如，对于那些城乡地区（具有城市和乡村特征的区域）。

# caption 的算法流程
整体可以分为两步 
> 1、图像理解
**目的：**识别图像中的对象，分析其属性，以及对象之间的相互作用关系
**常用方法**：
1）基于区域特征的方法
提取单独区域特征，并基于多个图像区域分析图像内容
2）基于全局特征的方法
> 2、语言生成
基于图像内容排列单词生成有意义的句子。

### ground elements 分为三个层次
> 为了获得遥感图像全面而详细的描述，本文的方法把一些典型的ground element分为以下三个层次：

>* 1、Key-Instance：飞机，油罐和船舶
>* 2、Envi-Element：机场、港口、建筑物、农田
>* 3、Landscape：城市、郊区、海洋、山脉
![](https://i.loli.net/2019/07/24/5d38061a3726782391.png)
图1 多级元素
> ![](https://i.loli.net/2019/07/24/5d38094f8534790074.png)
 图2 本文整体方法 图像理解（FCN）+语句生成
 
 
## 多层图像理解

### FCN 做图像处理
> FCNs(全卷积神经网络)是专门为**任意大小**的输入图像预测**二维标签图(2-D label map)**而不是cnn的单一标签。 -->>>>> 极大提高了处理灵活性和计算效率。

>* **输入任意大小的图片**
由于卷积运算不会限制输入图像大小，FCN允许任意大小的输入图像，而在经典CNN模型中，输入图像大小必须固定。
1、FCN以这种方式设计用于预测像素化**输出标签映射**而不是用于任意化输入图像的单个类别标签。
2、FCN像素到像素输出图自然地保留了**遥感图像的空间信息**，这使其适合我们的需要。

### 网络结构
FCN模型的输入包含三个部分**（key instance detection；envi- element analysis；landscape analysis）**
![](https://i.loli.net/2019/07/24/5d38336d69abb21780.png)

### 接受场（Receptive Field）
> 具有较大接收场的网络倾向于捕获较大规模的结构信息，例如环境元素和景观，而较小的网络可以更多地集中于诸如关键实例的外观之类的本地细节。

## 损失层设计




## Language Generation
#### 使用传统方法的原因
> 1、这些基于学习的模型是基于大量带注释的句子（通常是数百万个语料库）进行训练的，而目前我们还没有这种用于遥感图像的语料库。
2、使用**预定义模板**，可以根据遥感图像的特性和我们的特定需求轻松设计新模板并生成新规则。

#### 遥感图像的表示空间通过三元组来排列 **{ELM,ATR,RLT}**
![](https://i.loli.net/2019/07/25/5d3926c295eac10523.png)
>* ELM:指的是不同层次的ground element。
* ATR：指的是数量，大小和位置等属性。
* RLT：指的是不同元素之间的关系。

可以将可能的模板句子定义为：
{Prefix，<#E1，E1>，Prep，<#E2,E2>}

* Ei：ground element的名字
* #Ei:是实例Ei的数量
* Prep：一组相互作用关系{"by"，"on the left side of"...}
* Prefix：定义句子前缀的集合{“This is a picture of,”"This image show,"...}
* 之后，通过语法规则检查生成的句子，并纠正一些语言错误。
>* 对于**Prefix design**，在自然图像字幕中有两种常见的观点。
1、忽略句子的前缀，因为它没有为机器学习应用程序提供额外的信息，例如基于内容的图像检索。
2、添加一个prefix有时是有意义的并且应该特别添加到一些面向人类的应用程序。


### 语句生成阶段需要注意的问题
>* 1、【由于自然图像与遥感图像的额视角不同，所以各元素之间的关系也不同】
需要对基本要素之间的**相互作用和关系**进行全面分析，以产生有意义的句子。遥感图像与自然图像之间的主要区别在于它们的投影关系：一个是从人眼的日常生活角度拍摄的，另一个是在头部上方拍摄的。在自然图像中，人们倾向于关注三维空间的相互作用，例如“前后”和“上下”。但是，在遥感图像中，我们应该更加注意地面距离和方向，例如“近和远”，“左和右”。
* 2、【每个实例的属性】
确定关键实例的属性同样重要，例如数量和大小。此过程高度依赖于每个实例的正确位置。为了提取每个实例的边界框位置，我们使用基于每个尺度的检测图的非最大抑制。还应该注意的是，诸如“近和远”，“大和小”等基础元素的属性与图像分辨率及其特定类密切相关。例如，尺寸为80像素，1米/像素分辨率的飞机应称为“大型”飞机，而尺寸小于2米/像素分辨率的飞机可称为“中型”飞机。
* 3、【提取关键性信息】
在上述基础上，描述应该简明扼要，因为人们倾向于描述图像中最重要的对象或事件。在我们的方法中，我们只选择性地描述每个语义级别得分最高的前一个或前两个元素，而省略其他细节。

