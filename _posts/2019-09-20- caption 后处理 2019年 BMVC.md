---
layout: post
title:  "Look and Modify: Modification Networks for Image Captioning"
date:   2019-09-20 10:18:54
categories: 论文解读
tags:    caption 2019年 BMVC
---

* content
{:toc}

---
基于注意力的神经编码器解码器框架已被广泛用于image captioning。 其中许多框架仅仅依靠**image features** 或**object detection regional features**，将其全部重点部署在从头开始生成标题上。在本文中，我们介绍了一个新的框架，通过对剩余信息（residual information）进行建模，从给定的框架中学习对现有caption的修改，其中模型在每个时间步骤中学习**保留、删除或添加**什么到现有的caption中，允许模型完全关注“修改什么”而不是“预测什么”。我们在coco数据集上评估我们的方法，在几个image caption框架上进行测试训练，并表明我们的模型成功地修改了标题，使标题具有更好的评价分数。
[源码地址](https://github.com/fawazsammani/look-and-modify)
---

# 论文目的
本篇论文的中心思想就是针对生成效果不好的caption描述，采用后处理的方法对这些caption进行处理。
-- 其中一个创新点就是如何选择需要修改的单词，也就是采用一个** Residual Gating**
![image.png](https://i.loli.net/2020/02/25/1uzDanXdyfbC67O.png)
![实验对比图](https://i.loli.net/2020/02/25/wPC2G97l8UYInkZ.png)
通过上图的实验对比图可以明显的看出，当小于一定的阈值的时候，说明要对当前的词（非视觉词）进行修正。
# 论文思想
![主要框架图](https://i.loli.net/2020/02/25/K9j5IV36sJxHdy4.png)
以红线为分割线，可以分为左右两个部分。其中最主要的部分还是右边的剩余门控
## Residual Gating
![image.png](https://i.loli.net/2020/02/25/kmPGcA6ervtDzl9.png)
Residual Gating 输出一个修改门，然后与句子嵌入相乘，以产生编码句子的相应部分。这个门类似于LSTM门，因此可以被认为是LSTM单元的扩展。为了计算解码器已经知道到目前为止已经生成了什么的潜在状态，我们利用了视觉哨兵，分别对存储在内存单元中的信息进行建模。
在第一部分的公式中**g<sub>s</sub>**是门控单元
**s<sub>t</sub>** 是视觉哨兵输出
**g<sub>r</sub>**是用来计算**s<sub>t</sub>**（通过decoder得到的caption）和 **e**（现存的caption描述）的相似度。
**w<sub>ft</sub>** 现有标题的一部分（通过门控信号和现有caption相乘得到）
最后得到模型的输出：**o<sub>t</sub> = w<sub>ft</sub> + h<sub>t</sub>**
其中**h<sub>t</sub>**就是residual information

## Deep Averaging Network (DAN)
该模块的主要功能是提取语义特征
![DAN公式](https://i.loli.net/2020/02/25/JMiBxCFIPL19VRo.png)

## LSTM部分
![language LSTM](https://i.loli.net/2020/02/25/dfQ3LESupZzUJnB.png)
![Attention LSTM ](https://i.loli.net/2020/02/25/XzCmu3HwIcpVWAU.png)
##  属性提取模块
![属性提取模块](https://i.loli.net/2020/02/25/xscNJ3AYE6pkyKV.png)
# 实验结果
![实验结果对比图](https://i.loli.net/2020/02/25/aZK9pARclV3ndqQ.png)

---
- 通过实验结果就可以明显的看出本文中提出的方法只是针对初期生成效果差的方法，对于评价指标高，生成句子好的方法，修正的效果并不大。

---
